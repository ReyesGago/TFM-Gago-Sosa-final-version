{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPkmF6iESB-h"
   },
   "source": [
    "## Proposal for faster context extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\eneas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\eneas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12109,
     "status": "ok",
     "timestamp": 1740129144108,
     "user": {
      "displayName": "Reyes Gago Sosa",
      "userId": "00547146574573992582"
     },
     "user_tz": -60
    },
    "id": "CXpXPXDlSE6_",
    "outputId": "ccf83bc9-3aa4-43d2-b278-02c5052e81ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ eragile: 426 occurrences in 186 file(s)\n",
      "✅ garbiketa: 363 occurrences in 103 file(s)\n",
      "✅ izozte: 4 occurrences in 2 file(s)\n",
      "✅ ezaugarri organoleptiko: 3 occurrences in 3 file(s)\n",
      "✅ hauskortasun: 16 occurrences in 8 file(s)\n",
      "✅ elikagai: 696 occurrences in 203 file(s)\n",
      "✅ balioztapen: 6 occurrences in 3 file(s)\n",
      "✅ estalki: 34 occurrences in 21 file(s)\n",
      "✅ trinkotasun: 2 occurrences in 2 file(s)\n",
      "✅ berogailu: 4 occurrences in 4 file(s)\n",
      "✅ urradura: 9 occurrences in 5 file(s)\n",
      "✅ ioi: 184 occurrences in 61 file(s)\n",
      "✅ talka: 32 occurrences in 25 file(s)\n",
      "✅ jalkin: 2 occurrences in 2 file(s)\n",
      "✅ betetze: 36 occurrences in 14 file(s)\n",
      "✅ xafla: 171 occurrences in 46 file(s)\n",
      "✅ beira: 59 occurrences in 19 file(s)\n",
      "✅ indargetzaile: 28 occurrences in 12 file(s)\n",
      "❌ oxidazio-prozesu: Not found in any file\n",
      "✅ eragin: 3016 occurrences in 794 file(s)\n",
      "✅ pikor: 105 occurrences in 16 file(s)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "def get_unique_terms(file_path):\n",
    "    \"\"\"\n",
    "    Extracts unique terms from the first column of an Excel file or CSV file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the Excel file or CSV file.\n",
    "\n",
    "    Returns:\n",
    "        set: A set of unique terms.\n",
    "    \"\"\"\n",
    "    if file_path.endswith(\".xlsx\"):\n",
    "        df = pd.read_excel(file_path, engine='openpyxl')\n",
    "    elif file_path.endswith(\".csv\"):\n",
    "        df = pd.read_csv(file_path, engine='python')\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "    first_column = df.columns[0]\n",
    "    terms = set(df[first_column].dropna().astype(str).str.strip())\n",
    "    return terms\n",
    "\n",
    "# Get the context of each occurrence of a term in all text files within a folder\n",
    "def get_term_context(term, text_folder, context_chars=200):\n",
    "    \"\"\"\n",
    "    Finds the context of a term in text files within a folder.\n",
    "\n",
    "    Args:\n",
    "        term (str): The term to search for.\n",
    "        text_folder (str): Path to the folder containing text files.\n",
    "        context_chars (int): Number of characters to include before and after the term.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A list of contexts and the number of files where the term was found.\n",
    "    \"\"\"\n",
    "    pattern = rf\"\\b{re.escape(term)}\\b\"\n",
    "    contexts = []\n",
    "    found_files = set()\n",
    "    for file_name in os.listdir(text_folder):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(text_folder, file_name)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            found = False\n",
    "            for match in re.finditer(pattern, content, re.IGNORECASE):\n",
    "                if not found:\n",
    "                    found_files.add(file_name)\n",
    "                    found = True\n",
    "                start = max(0, match.start() - context_chars)\n",
    "                end = min(len(content), match.end() + context_chars)\n",
    "                context = content[start:end].replace(\"\\n\", \" \")\n",
    "                highlighted_term = f\"**{content[match.start():match.end()]}**\"\n",
    "                highlighted_context = (\n",
    "                    context[: match.start() - start]\n",
    "                    + highlighted_term\n",
    "                    + context[match.end() - start :]\n",
    "                )\n",
    "                contexts.append(highlighted_context.strip())\n",
    "    return contexts, len(found_files)\n",
    "\n",
    "# Main function to search terms and save results\n",
    "def search_terms_and_save(input_excel, text_folder, output_txt_path, output_csv_path, output_log_path):\n",
    "    \"\"\"\n",
    "    Searches for terms in text files and saves the results in TXT, CSV, and log files.\n",
    "\n",
    "    Args:\n",
    "        input_excel (str): Path to the Excel file containing terms.\n",
    "        text_folder (str): Path to the folder containing text files.\n",
    "        output_txt_path (str): Path to save the TXT file with contexts.\n",
    "        output_csv_path (str): Path to save the CSV file with contexts.\n",
    "        output_log_path (str): Path to save the log file with statistics.\n",
    "    \"\"\"\n",
    "    unique_terms = get_unique_terms(input_excel)\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as txt_out, \\\n",
    "            open(output_csv_path, 'w', encoding='utf-8', newline='') as csv_out, \\\n",
    "            open(output_log_path, 'w', encoding='utf-8') as log_out:\n",
    "        csv_writer = csv.writer(csv_out)\n",
    "        csv_writer.writerow([\"Term\", \"Context\", \"Occurrences\"])\n",
    "        for term in unique_terms:\n",
    "            contexts, num_files = get_term_context(term, text_folder)\n",
    "            occurrences = len(contexts)\n",
    "            # Write header in TXT\n",
    "            txt_out.write(f\"\\n=== {term.upper()} ({occurrences} occurrences in {num_files} file(s)) ===\\n\")\n",
    "            if occurrences > 0:\n",
    "                for i, context in enumerate(contexts, 1):\n",
    "                    txt_out.write(f\"{i}. ...{context}...\\n\")\n",
    "            else:\n",
    "                txt_out.write(\"Not found in the corpus.\\n\")\n",
    "\n",
    "            # Write to CSV\n",
    "            for context in contexts:\n",
    "                csv_writer.writerow([term, context, occurrences])\n",
    "\n",
    "            # Write message to console and log\n",
    "            message = (\n",
    "                f\"✅ {term}: {occurrences} occurrences in {num_files} file(s)\"\n",
    "                if occurrences > 0\n",
    "                else f\"❌ {term}: Not found in any file\"\n",
    "            )\n",
    "            print(message)\n",
    "            log_out.write(message + \"\\n\")\n",
    "\n",
    "\n",
    "# File paths\n",
    "input_excel = 'BA-ES-[Medical Sciences ~ Pharmaceutical Technology]_and_[Technological Sciences ~ Environmental technology and engineering].xlsx'\n",
    "text_folder = 'garaterm_full_corpora/osasuna'\n",
    "output_txt_path = 'contexts/context_terms_medicine_ba_es.txt'\n",
    "output_csv_path = 'contexts/context_terms_medicine_ba_es.csv'\n",
    "output_log_path = 'stats_medicine_ba_es.txt'\n",
    "\n",
    "# Execute\n",
    "search_terms_and_save(input_excel, text_folder, output_txt_path, output_csv_path, output_log_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNbwlP144T1e9sLFBTH2Xs0",
   "mount_file_id": "1KEZta2XQQ4DJZuhGl5TOnqB_lwqH3OFo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
